{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule to CVE BERT (WITH CLUSTER)**\n",
        "USE THE Bert MODEL WITH 5 EPOCH"
      ],
      "metadata": {
        "id": "GCxBFc_yVMwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trained Model"
      ],
      "metadata": {
        "id": "1UxA2oY0KGUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the datasets\n",
        "combined_df = pd.read_csv('combined_dataset_75training.csv')\n",
        "cve_df = pd.read_csv('Processed_CVE_withSpace.csv')\n",
        "\n",
        "# Ensure all entries are strings and fill NaN values\n",
        "combined_df['Best Matched Keywords'] = combined_df['Best Matched Keywords'].fillna(\"\").astype(str)\n",
        "combined_df['Processed Title + Description'] = combined_df['Processed Title + Description'].fillna(\"\").astype(str)\n",
        "combined_df['actionTitle'] = combined_df['actionTitle'].fillna(\"\").astype(str)\n",
        "combined_df['actionChannelTitle'] = combined_df['actionChannelTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerTitle'] = combined_df['triggerTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerChannelTitle'] = combined_df['triggerChannelTitle'].fillna(\"\").astype(str)\n",
        "cve_df['Processed_Text'] = cve_df['Processed_Text'].fillna(\"\").astype(str)\n",
        "\n",
        "# Combine columns\n",
        "combined_texts = (\n",
        "    combined_df['triggerTitle'] + \" \" +\n",
        "    combined_df['triggerChannelTitle'] + \" \" +\n",
        "    combined_df['actionTitle'] + \" \" +\n",
        "    combined_df['actionChannelTitle'] + \" \" +\n",
        "    combined_df['Processed Title + Description'] + \" \" +\n",
        "    combined_df['Best Matched Keywords']\n",
        ").tolist()\n",
        "cve_texts = cve_df['Processed_Text'].tolist()\n",
        "\n",
        "# Define a custom Dataset class\n",
        "class TextPairDataset(Dataset):\n",
        "    def __init__(self, pairs, tokenizer, max_length=64):\n",
        "        self.pairs = pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text1, text2, label = self.pairs[idx]\n",
        "        inputs = self.tokenizer(text1, text2, return_tensors='pt', max_length=self.max_length, truncation=True, padding='max_length')\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
        "        inputs['labels'] = torch.tensor(float(label), dtype=torch.float)\n",
        "        return inputs\n",
        "\n",
        "# Initialize tokenizer and model with condition for device\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# Define the model with an added dense layer\n",
        "class SimilarityModel(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(SimilarityModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dense = nn.Linear(768, 256)\n",
        "        self.regressor = nn.Linear(256, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        dense_output = self.relu(self.dense(pooled_output))\n",
        "        return self.regressor(dense_output)\n",
        "\n",
        "# Instantiate the model, criterion, optimizer, and scheduler\n",
        "model = SimilarityModel(bert_model).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=2e-5)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "# Prepare data for training (create pairs and limit negatives for balanced training)\n",
        "pairs = [(combined_texts[i], cve_texts[i], 1) for i in range(min(len(combined_texts), len(cve_texts)))]\n",
        "pairs += [(combined_texts[i], cve_texts[j], 0) for i in range(len(combined_texts)) for j in range(len(cve_texts)) if i != j]\n",
        "num_positive_samples = len([pair for pair in pairs if pair[2] == 1])\n",
        "num_negative_samples = min(num_positive_samples * 2, len([pair for pair in pairs if pair[2] == 0]))\n",
        "positive_pairs = [pair for pair in pairs if pair[2] == 1]\n",
        "negative_pairs = random.sample([pair for pair in pairs if pair[2] == 0], num_negative_samples)\n",
        "pairs = positive_pairs + negative_pairs\n",
        "random.shuffle(pairs)\n",
        "\n",
        "# Create the DataLoader\n",
        "train_dataset = TextPairDataset(pairs, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop with gradient clipping and learning rate scheduler\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss / len(train_loader)}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model_dir = 'final_trained_model_similarity5'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "model.bert.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "print(\"Model and tokenizer saved.\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "print(\"Loading model from local path...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "bert_model = BertModel.from_pretrained(model_dir)"
      ],
      "metadata": {
        "id": "gq4mVXxKKJOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Number of Cluster (using Elbow point)"
      ],
      "metadata": {
        "id": "lIyazhkHKTJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model path\n",
        "model_dir = 'final_trained_model_similarity5'\n",
        "\n",
        "# Reload the model and tokenizer\n",
        "print(\"Reloading the model and tokenizer from local path...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "bert_model = BertModel.from_pretrained(model_dir).eval()\n",
        "print(\"Model and tokenizer reloaded successfully.\")\n",
        "\n",
        "# Load the datasets\n",
        "combined_df = pd.read_csv('combined_dataset_75training.csv')\n",
        "cve_df = pd.read_csv('Processed_CVE_withSpace.csv')\n",
        "\n",
        "# Ensure all entries are strings and fill NaN values\n",
        "combined_df['Best Matched Keywords'] = combined_df['Best Matched Keywords'].fillna(\"\").astype(str)\n",
        "combined_df['Processed Title + Description'] = combined_df['Processed Title + Description'].fillna(\"\").astype(str)\n",
        "combined_df['actionChannelTitle'] = combined_df['actionChannelTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerChannelTitle'] = combined_df['triggerChannelTitle'].fillna(\"\").astype(str)\n",
        "cve_df['Processed_Text'] = cve_df['Processed_Text'].fillna(\"\").astype(str)\n",
        "\n",
        "# Combine columns for rule text input in each entry\n",
        "combined_texts = (\n",
        "    combined_df['Best Matched Keywords'] + \" \" +\n",
        "    combined_df['Processed Title + Description'] + \" \" +\n",
        "    combined_df['actionChannelTitle'] + \" \" +\n",
        "    combined_df['triggerChannelTitle']\n",
        ").tolist()\n",
        "cve_texts = cve_df['Processed_Text'].tolist()\n",
        "\n",
        "# Function to compute embeddings using the model\n",
        "def compute_embeddings(texts, model, tokenizer, max_length=64):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length').to('cpu')\n",
        "        with torch.no_grad():\n",
        "            embedding = model(**inputs).pooler_output\n",
        "        embeddings.append(embedding.squeeze().cpu().numpy())\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# Compute embeddings for combined_texts and cve_texts\n",
        "print(\"Computing embeddings...\")\n",
        "combined_embeddings = compute_embeddings(combined_texts, bert_model, tokenizer)\n",
        "cve_embeddings = compute_embeddings(cve_texts, bert_model, tokenizer)\n",
        "print(\"Embeddings computed successfully.\")\n",
        "\n",
        "# Calculate inertia for each cluster count to identify the \"elbow\" point\n",
        "inertias = []\n",
        "cluster_counts = range(2, 101)\n",
        "\n",
        "for k in cluster_counts:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(cve_embeddings)  # Fit on CVE embeddings\n",
        "    inertias.append(kmeans.inertia_)  # Store inertia value for each k\n",
        "    print(f\"k={k}: Inertia={kmeans.inertia_}\")\n",
        "\n",
        "# Plot inertia values for each cluster count\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(cluster_counts, inertias, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Identify the primary elbow point and top 10 elbow points\n",
        "from kneed import KneeLocator\n",
        "kneedle = KneeLocator(cluster_counts, inertias, curve='convex', direction='decreasing')\n",
        "primary_elbow = kneedle.elbow\n",
        "print(f\"Primary elbow point: {primary_elbow}\")\n",
        "\n",
        "# Calculate the top 10 elbow points based on the largest drops in inertia\n",
        "inertia_drops = np.diff(inertias)\n",
        "top_10_drop_indices = np.argsort(inertia_drops)[-10:][::-1] + 2\n",
        "\n",
        "print(f\"Top 10 elbow points based on the largest inertia drops: {sorted(top_10_drop_indices)}\")\n",
        "\n",
        "# Highlight primary and top elbow points on the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(cluster_counts, inertias, marker='o', linestyle='-', color='b')\n",
        "plt.axvline(x=primary_elbow, color='r', linestyle='--', label=f'Primary Elbow at k={primary_elbow}')\n",
        "for k in sorted(top_10_drop_indices):\n",
        "    plt.axvline(x=k, color='g', linestyle='--', alpha=0.5)\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method with Highlighted Elbow Points\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6brGXYyvKZtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING (mapping rule to cve)"
      ],
      "metadata": {
        "id": "czf_8tQ1bJZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Define paths and load model\n",
        "model_dir = './20C'  # Path to your pre-trained model directory\n",
        "\n",
        "# Load the tokenizer and the pre-trained BERT model from the local folder\n",
        "print(f\"Loading model from {model_dir}...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "bert_model = BertModel.from_pretrained(model_dir)  # For embedding extraction, we use BertModel\n",
        "\n",
        "# 2. Load datasets and preprocess them\n",
        "combined_df = pd.read_csv('combined_dataset_75training.csv')\n",
        "cve_df = pd.read_csv('Processed_CVE_withSpace.csv')\n",
        "\n",
        "# Preprocess text data to ensure they are clean and consistent\n",
        "combined_df['Best Matched Keywords'] = combined_df['Best Matched Keywords'].fillna(\"\").astype(str)\n",
        "combined_df['Processed Title + Description'] = combined_df['Processed Title + Description'].fillna(\"\").astype(str)\n",
        "combined_df['actionChannelTitle'] = combined_df['actionChannelTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerChannelTitle'] = combined_df['triggerChannelTitle'].fillna(\"\").astype(str)\n",
        "cve_df['Processed_Text'] = cve_df['Processed_Text'].fillna(\"\").astype(str)\n",
        "\n",
        "# Concatenate all text columns in combined_df that need to be tokenized\n",
        "combined_df['all_text'] = (combined_df['Best Matched Keywords'] + \" \" +\n",
        "                           combined_df['Processed Title + Description'] + \" \" +\n",
        "                           combined_df['actionChannelTitle'] + \" \" +\n",
        "                           combined_df['triggerChannelTitle'])\n",
        "\n",
        "# 3. Define function to compute embeddings\n",
        "def compute_embeddings(texts, model, tokenizer, max_length=64):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length').to('cpu')\n",
        "        with torch.no_grad():\n",
        "            embedding = model(**inputs).pooler_output\n",
        "        embeddings.append(embedding.squeeze().cpu().numpy())\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# 4. Compute embeddings for combined texts and CVE texts\n",
        "combined_texts = combined_df['all_text'].fillna('').tolist()\n",
        "cve_texts = cve_df['Processed_Text'].fillna('').tolist()\n",
        "\n",
        "combined_embeddings = compute_embeddings(combined_texts, bert_model, tokenizer)\n",
        "cve_embeddings = compute_embeddings(cve_texts, bert_model, tokenizer)\n",
        "\n",
        "# 5.  the KMeans model\n",
        "num_clusters = 20\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "cve_clusters = kmeans.fit_predict(cve_embeddings)\n",
        "\n",
        "kmeans_model_path = './kmeans_model_FRI.pkl'\n",
        "joblib.dump(kmeans, kmeans_model_path)  # Save the KMeans model\n",
        "print(f\"KMeans model saved to {kmeans_model_path}\")\n",
        "\n",
        "\n",
        "# 6. Step 3: Map each combined text to the closest cluster center\n",
        "combined_clusters = []\n",
        "for embedding in combined_embeddings:\n",
        "    distances = cosine_similarity([embedding], kmeans.cluster_centers_)\n",
        "    closest_cluster = np.argmax(distances)\n",
        "    combined_clusters.append(closest_cluster)\n",
        "\n",
        "\n",
        "\n",
        "similarity_threshold = 0.7\n",
        "\n",
        "# 7. Step 4: Check cluster match and similarity, record results\n",
        "correct_matches = 0\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "output_data = {\n",
        "    'combined_text': [],\n",
        "    'title': [],\n",
        "    'desc': [],\n",
        "    'cve_name': [],\n",
        "    'cve_text': [],\n",
        "    'cve_full_text': [],\n",
        "    'assigned_cluster': [],\n",
        "    'similarity_score': [],\n",
        "    'correctly_mapped_cluster': []\n",
        "}\n",
        "\n",
        "# For each combined text, check if it maps to a CVE text based on similarity score\n",
        "for i, (combined_cluster, combined_text) in enumerate(zip(combined_clusters, combined_texts)):\n",
        "    combined_embedding = combined_embeddings[i].reshape(1, -1)\n",
        "    similarities = cosine_similarity(combined_embedding, cve_embeddings).flatten()\n",
        "    best_match_idx = np.argmax(similarities)\n",
        "    best_similarity = similarities[best_match_idx]\n",
        "\n",
        "    # Get the best matching CVE text and its cluster\n",
        "    true_cve_cluster = cve_clusters[best_match_idx]\n",
        "    cve_name = cve_df.iloc[best_match_idx]['Name'] if 'Name' in cve_df.columns else 'N/A'\n",
        "    cve_text = cve_df.iloc[best_match_idx]['Processed_Text']\n",
        "    cve_full_text = cve_df.iloc[best_match_idx]['Text']  # Full text column from CVE dataset\n",
        "\n",
        "    if combined_cluster == true_cve_cluster and best_similarity >= similarity_threshold:\n",
        "        is_correct = 1\n",
        "        correct_matches += 1\n",
        "\n",
        "    predicted_labels.append(combined_cluster)\n",
        "    true_labels.append(true_cve_cluster)\n",
        "\n",
        "    # Collect data for review\n",
        "    output_data['combined_text'].append(combined_text)\n",
        "    output_data['title'].append(combined_df.iloc[i]['title'])\n",
        "    output_data['desc'].append(combined_df.iloc[i]['desc'])\n",
        "    output_data['cve_name'].append(cve_name)\n",
        "    output_data['cve_text'].append(cve_text)\n",
        "    output_data['cve_full_text'].append(cve_full_text)\n",
        "    output_data['assigned_cluster'].append(combined_cluster)\n",
        "    output_data['similarity_score'].append(best_similarity)\n",
        "    output_data['correctly_mapped_cluster'].append(is_correct)\n",
        "\n",
        "# 9. Calculate cluster-based accuracy\n",
        "cluster_accuracy = correct_matches / len(combined_texts) * 100\n",
        "print(f\"Cluster-Based Accuracy: {cluster_accuracy:.2f}%\")\n",
        "\n",
        "# 10. Calculate precision, recall, and F1-score ( macro)\n",
        "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# 11. Save results to CSV for further analysis\n",
        "output_df = pd.DataFrame(output_data)\n",
        "output_file = 'PRE_FRI_TRAIN_CVE_BERTresults.csv'\n",
        "output_df.to_csv(output_file, index=False)\n",
        "print(f\"Cluster-based evaluation results saved to '{output_file}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JAAiP-ybNF2",
        "outputId": "9c159035-476a-4744-8fc0-ddf0cb075711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./20C...\n",
            "KMeans model saved to ./kmeans_model_FRI.pkl\n",
            "Cluster-Based Accuracy: 82.87%\n",
            "Precision: 0.67\n",
            "Recall: 0.66\n",
            "F1-Score: 0.63\n",
            "Cluster-based evaluation results saved to 'PRE_FRI_TRAIN_CVE_BERTresults.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING ( Cluster)"
      ],
      "metadata": {
        "id": "odwBdghabC9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#1.Loading\n",
        "model_dir = './20C'\n",
        "kmeans_model_path = './kmeans_model_FRI.pkl'\n",
        "\n",
        "print(f\"Loading model from {model_dir}...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "bert_model = BertModel.from_pretrained(model_dir)  # For embedding extraction, we use BertModel\n",
        "\n",
        "combined_df = pd.read_csv('combined_dataset_25testing.csv')\n",
        "cve_df = pd.read_csv('Processed_CVE_withSpace.csv')\n",
        "\n",
        "# Preprocess text data to ensure they are clean and consistent\n",
        "combined_df['Best Matched Keywords'] = combined_df['Best Matched Keywords'].fillna(\"\").astype(str)\n",
        "combined_df['Processed Title + Description'] = combined_df['Processed Title + Description'].fillna(\"\").astype(str)\n",
        "combined_df['actionChannelTitle'] = combined_df['actionChannelTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerChannelTitle'] = combined_df['triggerChannelTitle'].fillna(\"\").astype(str)\n",
        "cve_df['Processed_Text'] = cve_df['Processed_Text'].fillna(\"\").astype(str)\n",
        "\n",
        "# 2.to combined_df\n",
        "combined_df['all_text'] = (combined_df['Best Matched Keywords'] + \" \" +\n",
        "                           combined_df['Processed Title + Description'] + \" \" +\n",
        "                           combined_df['actionChannelTitle'] + \" \" +\n",
        "                           combined_df['triggerChannelTitle'])\n",
        "\n",
        "# 3. compute embeddings\n",
        "def compute_embeddings(texts, model, tokenizer, max_length=64):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length').to('cpu')\n",
        "        with torch.no_grad():\n",
        "            embedding = model(**inputs).pooler_output\n",
        "        embeddings.append(embedding.squeeze().cpu().numpy())\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# compute embeddings combined texts and CVE texts\n",
        "combined_texts = combined_df['all_text'].fillna('').tolist()\n",
        "cve_texts = cve_df['Processed_Text'].fillna('').tolist()\n",
        "\n",
        "combined_embeddings = compute_embeddings(combined_texts, bert_model, tokenizer)\n",
        "cve_embeddings = compute_embeddings(cve_texts, bert_model, tokenizer)\n",
        "\n",
        "cve_clusters = kmeans.fit_predict(cve_embeddings)\n",
        "\n",
        "# 5. Load the pre-trained KMeans model\n",
        "kmeans = joblib.load(kmeans_model_path)\n",
        "print(f\"KMeans model loaded from {kmeans_model_path}\")\n",
        "\n",
        "# 6. Map each combined text to the closest cluster center\n",
        "combined_clusters = []\n",
        "for embedding in combined_embeddings:\n",
        "    distances = cosine_similarity([embedding], kmeans.cluster_centers_)\n",
        "    closest_cluster = np.argmax(distances)\n",
        "    combined_clusters.append(closest_cluster)\n",
        "\n",
        "\n",
        "similarity_threshold = 0.7\n",
        "\n",
        "# 7. Check cluster match and similarity, record results\n",
        "correct_matches = 0\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "output_data = {\n",
        "    'combined_text': [],\n",
        "    'title': [],\n",
        "    'desc': [],\n",
        "    'cve_name': [],\n",
        "    'cve_text': [],\n",
        "    'cve_full_text': [],\n",
        "    'assigned_cluster': [],\n",
        "    'similarity_score': [],\n",
        "    'correctly_mapped_cluster': []\n",
        "}\n",
        "\n",
        "# For each combined text, check if it maps to a CVE text based on similarity score\n",
        "for i, (combined_cluster, combined_text) in enumerate(zip(combined_clusters, combined_texts)):\n",
        "    combined_embedding = combined_embeddings[i].reshape(1, -1)\n",
        "    similarities = cosine_similarity(combined_embedding, cve_embeddings).flatten()\n",
        "    best_match_idx = np.argmax(similarities)\n",
        "    best_similarity = similarities[best_match_idx]\n",
        "\n",
        "    # Get the best matching CVE text and its cluster\n",
        "    true_cve_cluster = cve_clusters[best_match_idx]\n",
        "    cve_name = cve_df.iloc[best_match_idx]['Name'] if 'Name' in cve_df.columns else 'N/A'\n",
        "    cve_text = cve_df.iloc[best_match_idx]['Processed_Text']\n",
        "    cve_full_text = cve_df.iloc[best_match_idx]['Text']\n",
        "\n",
        "\n",
        "    if  combined_cluster == true_cve_cluster and best_similarity >= similarity_threshold:\n",
        "        is_correct = 1\n",
        "        correct_matches += 1\n",
        "\n",
        "    predicted_labels.append(combined_cluster)\n",
        "    true_labels.append(true_cve_cluster)\n",
        "\n",
        "\n",
        "    output_data['combined_text'].append(combined_text)\n",
        "    output_data['title'].append(combined_df.iloc[i]['title'])\n",
        "    output_data['desc'].append(combined_df.iloc[i]['desc'])\n",
        "    output_data['cve_name'].append(cve_name)\n",
        "    output_data['cve_text'].append(cve_text)\n",
        "    output_data['cve_full_text'].append(cve_full_text)\n",
        "    output_data['assigned_cluster'].append(combined_cluster)\n",
        "    output_data['similarity_score'].append(best_similarity)\n",
        "    output_data['correctly_mapped_cluster'].append(is_correct)\n",
        "\n",
        "# 9. Calculate cluster-based accuracy\n",
        "cluster_accuracy = correct_matches / len(combined_texts) * 100\n",
        "print(f\"Cluster-Based Accuracy: {cluster_accuracy:.2f}%\")\n",
        "\n",
        "# 10. Calculate precision, recall, and F1-score\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# 11. Save results to CSV for further analysis\n",
        "output_df = pd.DataFrame(output_data)\n",
        "output_file = 'PRE_FRI_TEST_CVE_BERTresults2.csv'\n",
        "output_df.to_csv(output_file, index=False)\n",
        "print(f\"Cluster-based evaluation results saved to '{output_file}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz_Qkzz_zW5P",
        "outputId": "e266219a-6b04-4cf3-a892-9d690aa7cdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./20C...\n",
            "KMeans model loaded from ./kmeans_model_FRI.pkl\n",
            "Cluster-Based Accuracy: 81.85%\n",
            "Precision: 0.84\n",
            "Recall: 0.82\n",
            "F1-Score: 0.82\n",
            "Cluster-based evaluation results saved to 'PRE_FRI_TEST_CVE_BERTresults2.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3XrCBwUIpkI",
        "outputId": "bf333d72-a393-4590-bb35-5fc1064f52d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPERT (without Cluster)"
      ],
      "metadata": {
        "id": "mg3CzrtU9fX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "# 1. Loading\n",
        "model_dir = './20C'\n",
        "\n",
        "print(f\"Loading model from {model_dir}...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "bert_model = BertModel.from_pretrained(model_dir)\n",
        "\n",
        "combined_df = pd.read_csv('combined_dataset_25testing.csv')\n",
        "cve_df = pd.read_csv('Processed_CVE_withSpace.csv')\n",
        "rule_to_cve_mapping_df = pd.read_csv('Complete_Rule_to_CVE_Mapping_with_Full_Details.csv')\n",
        "\n",
        "# Preprocess text data to ensure they are clean and consistent\n",
        "combined_df['Best Matched Keywords'] = combined_df['Best Matched Keywords'].fillna(\"\").astype(str)\n",
        "combined_df['Processed Title + Description'] = combined_df['Processed Title + Description'].fillna(\"\").astype(str)\n",
        "combined_df['actionChannelTitle'] = combined_df['actionChannelTitle'].fillna(\"\").astype(str)\n",
        "combined_df['triggerChannelTitle'] = combined_df['triggerChannelTitle'].fillna(\"\").astype(str)\n",
        "cve_df['Processed_Text'] = cve_df['Processed_Text'].fillna(\"\").astype(str)\n",
        "\n",
        "# 2. combined_df\n",
        "combined_df['all_text'] = (combined_df['Best Matched Keywords'] + \" \" +\n",
        "                           combined_df['Processed Title + Description'] + \" \" +\n",
        "                           combined_df['actionChannelTitle'] + \" \" +\n",
        "                           combined_df['triggerChannelTitle'])\n",
        "\n",
        "# 3.  compute embeddings\n",
        "def compute_embeddings(texts, model, tokenizer, max_length=64):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length').to('cpu')\n",
        "        with torch.no_grad():\n",
        "            embedding = model(**inputs).pooler_output\n",
        "        embeddings.append(embedding.squeeze().cpu().numpy())\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# 4. Compute embeddings for combined texts and CVE texts\n",
        "combined_texts = combined_df['all_text'].fillna('').tolist()\n",
        "cve_texts = cve_df['Processed_Text'].fillna('').tolist()\n",
        "\n",
        "combined_embeddings = compute_embeddings(combined_texts, bert_model, tokenizer)\n",
        "cve_embeddings = compute_embeddings(cve_texts, bert_model, tokenizer)\n",
        "\n",
        "# 7. Define the similarity threshold for similarity matching\n",
        "similarity_threshold = 0.7\n",
        "\n",
        "# 8. Compute keyword similarity (based on keyword overlap)\n",
        "def keyword_similarity(row_keywords, cve_keywords):\n",
        "    train_keywords_set = set(row_keywords.lower().split())\n",
        "    cve_keywords_set = set(cve_keywords.lower().split())\n",
        "    intersection = train_keywords_set.intersection(cve_keywords_set)\n",
        "    union = train_keywords_set.union(cve_keywords_set)\n",
        "    return len(intersection) / len(union) if union else 0\n",
        "\n",
        "# Calculate keyword similarities\n",
        "def compute_keyword_similarities(test_data, cve_data):\n",
        "    keyword_similarities = np.zeros((len(test_data), len(cve_data)))\n",
        "    for i, test_keywords in enumerate(test_data['Best Matched Keywords']):\n",
        "        for j, cve_keywords in enumerate(cve_data['Processed_Text']):\n",
        "            keyword_similarities[i, j] = keyword_similarity(test_keywords, cve_keywords)\n",
        "    return keyword_similarities\n",
        "\n",
        "keyword_similarities = compute_keyword_similarities(combined_df, cve_df)\n",
        "\n",
        "# 9. Combine BERT-based similarity and keyword similarity\n",
        "keyword_weight = 0.4\n",
        "combined_similarity = (1 - keyword_weight) * cosine_similarity(combined_embeddings, cve_embeddings) + keyword_weight * keyword_similarities\n",
        "\n",
        "# Normalize combined similarity to 0-1 range\n",
        "combined_similarity = (combined_similarity - combined_similarity.min()) / (combined_similarity.max() - combined_similarity.min())\n",
        "\n",
        "# 10. Check similarity, record results, and create 'correctly_mapped' column\n",
        "best_matches = combined_similarity.argmax(axis=1)\n",
        "best_scores = combined_similarity.max(axis=1)\n",
        "\n",
        "output_data = {\n",
        "    'combined_text': [],\n",
        "    'title': [],\n",
        "    'desc': [],\n",
        "    'cve_name': [],\n",
        "    'cve_text': [],\n",
        "    'cve_full_text': [],\n",
        "    'similarity_score': [],\n",
        "    'correctly_mapped': [],\n",
        "    'logical_match': []\n",
        "}\n",
        "\n",
        "for i, combined_text in enumerate(combined_texts):\n",
        "    # Get the best matching CVE text based on combined similarity\n",
        "    cve_name = cve_df.iloc[best_matches[i]]['Name'] if 'Name' in cve_df.columns else 'N/A'\n",
        "    cve_text = cve_df.iloc[best_matches[i]]['Processed_Text']\n",
        "    cve_full_text = cve_df.iloc[best_matches[i]]['Text']\n",
        "\n",
        "    if best_scores[i] >= similarity_threshold:\n",
        "        is_correct = 1\n",
        "    else:\n",
        "        is_correct = 0\n",
        "\n",
        "    # Directly use the Logical Match from rule_to_cve_mapping_df (aligned by index)\n",
        "    logical_match = rule_to_cve_mapping_df.iloc[i]['Logical Match']\n",
        "\n",
        "    # Collect data for review\n",
        "    output_data['combined_text'].append(combined_text)\n",
        "    output_data['title'].append(combined_df.iloc[i]['title'])\n",
        "    output_data['desc'].append(combined_df.iloc[i]['desc'])\n",
        "    output_data['cve_name'].append(cve_name)\n",
        "    output_data['cve_text'].append(cve_text)\n",
        "    output_data['cve_full_text'].append(cve_full_text)\n",
        "    output_data['similarity_score'].append(best_scores[i])\n",
        "    output_data['correctly_mapped'].append(is_correct)\n",
        "    output_data['logical_match'].append(logical_match)\n",
        "\n",
        "# 11. Calculate accuracy based on logical match and similarity\n",
        "correct_matches = sum([1 for i in range(len(output_data['correctly_mapped'])) if output_data['correctly_mapped'][i] == output_data['logical_match'][i]])\n",
        "accuracy = correct_matches / len(combined_texts) * 100\n",
        "print(f\"Accuracy based on logical match and similarity: {accuracy:.2f}%\")\n",
        "\n",
        "# 12. Print the classification report and other evaluation metrics\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"              --- Calculate ---              \")\n",
        "\n",
        "# 1. Print the classification report (precision, recall, F1-score for each class)\n",
        "print(\"Comparison with Expert Labels:\")\n",
        "print(classification_report(output_data['logical_match'], output_data['correctly_mapped']))\n",
        "\n",
        "# 2. Calculate and print overall accuracy\n",
        "accuracy = accuracy_score(output_data['logical_match'], output_data['correctly_mapped'])\n",
        "print(f\"Accuracy Compared to Expert Labels: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 3. Calculate and print precision, recall, and F1-score (using 'micro' average)\n",
        "precision = precision_score(output_data['logical_match'], output_data['correctly_mapped'], average='micro')\n",
        "recall = recall_score(output_data['logical_match'], output_data['correctly_mapped'], average='micro')\n",
        "f1 = f1_score(output_data['logical_match'], output_data['correctly_mapped'], average='micro')\n",
        "\n",
        "print(f\"Precision based on labels: {precision:.2f}\")\n",
        "print(f\"Recall based on labels: {recall:.2f}\")\n",
        "print(f\"F1-Score based on labels: {f1:.2f}\")\n",
        "print(f\"Accuracy based on labels: {accuracy:.2f}\")\n",
        "\n",
        "# 13. Save results to CSV for further analysis\n",
        "output_df = pd.DataFrame(output_data)\n",
        "output_file = '2Expert_Mapped_CVE_Results.csv'\n",
        "output_df.to_csv(output_file, index=False)\n",
        "print(f\"Evaluation results saved to '{output_file}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_rBb79ZoiWx",
        "outputId": "56736681-96fc-40bb-cd6f-c3c9969d11b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from ./20C...\n",
            "Accuracy based on logical match and similarity: 98.94%\n",
            "---------------------------------------------\n",
            "              --- Calculate ---              \n",
            "Comparison with Expert Labels:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.99      0.99      3978\n",
            "\n",
            "    accuracy                           0.99      3978\n",
            "   macro avg       0.50      0.49      0.50      3978\n",
            "weighted avg       1.00      0.99      0.99      3978\n",
            "\n",
            "Accuracy Compared to Expert Labels: 98.94%\n",
            "Precision based on labels: 0.99\n",
            "Recall based on labels: 0.99\n",
            "F1-Score based on labels: 0.99\n",
            "Accuracy based on labels: 0.99\n",
            "Evaluation results saved to '2Expert_Mapped_CVE_Results.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}